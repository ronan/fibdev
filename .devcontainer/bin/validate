#!/bin/bash


echo "
  â•â•¦â•â•â•â•â•—                         ğŸŒ¤ï¸
   â•‘  [ | ]
___â•©___      [  ][  ][  ]
\   ğŸ›Ÿ  |     [  ][  ][  ]  ________
 \     |_[  ][  ][  ][  ]_/ o o o /
  \______________________________/
ğŸŒŠğŸŒŠğŸŒŠğŸŒŠğŸŒŠğŸŒŠğŸŒŠğŸŒŠğŸŒŠğŸŒŠğŸŒŠğŸŒŠğŸŒŠğŸŒŠğŸŒŠğŸŒŠğŸŒŠğŸŒŠğŸŒŠğŸŒŠğŸŒŠğŸŒŠğŸŒŠğŸŒŠğŸŒŠ
ğŸŒŠğŸŒŠğŸŒŠğŸŒŠ Validating site with VRT. ğŸŒŠğŸŒŠğŸŒŠğŸŒŠğŸŒŠ
ğŸŒŠğŸŒŠğŸŒŠğŸŒŠğŸŒŠğŸŒŠğŸŒŠğŸŒŠğŸŒŠğŸŒŠğŸŒŠğŸŒŠğŸŒŠğŸŒŠğŸŒŠğŸŒŠğŸŒŠğŸŒŠğŸŒŠğŸŒŠğŸŒŠğŸŒŠğŸŒŠğŸŒŠğŸŒŠ
"

if [ ! -f /workspace/inbox/urls.txt ]
then 
    echo "ğŸ•·ï¸ Crawling site to gather urls to test"
    mkdir -p /data/wget
    cd /data/wget
    wget --spider \
         --recursive \
         --level=$DEPTH_TO_TEST \
         --level=5 \
         --max-redirect=0 \
         --delete-after \
         --domains=drupal \
         -e robots=off \
        http://drupal/ 2>&1 \
        | grep -B 3 "text/html" \
        | grep http \
        | awk '{ print $3 }' \
        | uniq \
        | sed "s|http://drupal||g" \
        > /workspace/outbox/urls.txt

    cp /workspace/outbox/urls.txt /workspace/inbox/urls.txt
fi

echo "ğŸ’ Creating a backstop.json file"
. /usr/bin/mo

# export TEST_URLS=(`head -n 50 /workspace/inbox/urls.txt | tr "\n" " "`)
cp -f /workspace/.devcontainer/backstop.js/backstop.config.js /workspace/data/backstop/backstop.config.js

echo "ğŸ§¹Clearing cache"
# app-cli cc all
# drush9 cache:rebuild
# drush10 cache:rebuild

echo "ğŸ‘“ Peforming visual regression test ..."
backstop reference
backstop test
echo "ğŸ“Š http://localhost:8100/"